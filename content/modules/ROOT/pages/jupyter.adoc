# Working with Jupyter Notebooks

Jupyter Notebooks are a great way to work with data science and machine learning projects. They allow you to write and execute Python code in a web-based interface, and they also allow you to include text, images, and other content in the same document. This makes them a great tool for data analysis, data visualization, and other tasks that involve working with data. Let's validate the notebook that was used to train the model. We'll also run the data science pipeline to automate the model construction process.

## Validating the training notebook

NOTE: No need to actually run the cells in the notebook, this is an example of the training process used by data scientists for the model we'll be using today.

Now, let's explore the validation notebook to understand how the data scientist created and trained the RoShambo game model. Navigate to the `rps-game/roshambo-notebooks` directory, and open the `validation.ipynb` notebook.  This notebook contains the step-by-step process of model creation, training, and validation.

image::openshift-ai-jupyter-notebook-validation.png[Jupyter Notebook Validation]

Here's a bit about the technical details of the model development process:

- The notebook starts by importing the necessary libraries, such as PyTorch, torchvision, and matplotlib, which are essential for model development and visualization.
- The pre-trained ResNet model is loaded using the `get_resnet()` function, which provides a powerful starting point for transfer learning.
- The dataset is loaded using the `get_ds_dl()` function, which prepares the data for training and testing. 
- The ONNX model is loaded using the `create_session()` function, which allows for efficient inference. 
- The model's performance is evaluated on the test set by iterating over the test images and comparing the predicted class with the actual label. 
- The notebook calculates the percentage of incorrect predictions and displays the distribution of incorrect predictions grouped by the true label and predicted class. 
- Finally, the notebook visualizes some of the incorrectly classified images for further analysis.

You'll also see in the `modelmesh/images` directory there are some examples used to test the model.

image::openshift-ai-jupyter-notebook-validation-modelmesh.png[Jupyter Notebook Validation ModelMesh]

## Run the Data Science Pipeline

With the model developed and validated in the notebook, let's leverage the power of Kubeflow and Tekton to automate the model construction process using a data science pipeline.

Navigate to the `rps-game/roshambo-notebooks/pipelines` directory, and open the `train.pipeline` file. This file contains an example of the pipeline definition which orchestrates the steps required to build, train, and validate the RoShambo game model.

image::openshift-ai-tekton-pipeline.png[Tekton Pipeline]

Here, simply run the pipeline from the *Start* button on the top of the pipeline view, which is using the open source Elyra project.

image::openshift-ai-tekton-pipeline-start.png[Tekton Pipeline Start]

You can easily monitor the pipeline execution progress in the OpenShift AI dashboard, using the 1:1 mapping from Jupyter Hub to OpenShift AI.


image::openshift-ai-tekton-pipeline-progress.png[Tekton Pipeline Progress]

Once the pipeline execution is complete, you can verify the presence of the trained model artifact in the OpenShift AI dashboard. The model artifact represents the final trained model that can be used for serving and inference. By running the data science pipeline, you automate the model construction process, ensuring reproducibility and enabling seamless integration with the overall ML workflow.

image::openshift-ai-tekton-pipeline-artifact.png[Tekton Pipeline Artifact]

## Next Steps

With our model developed and trained, we're now ready to serve it using the Model Server in OpenShift AI. In the next section, we'll create a Model Server and test the served model.